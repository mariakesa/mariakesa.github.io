<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
        .text {
            max-width: 600px; 
            text-align: left;
        }
    </style>
</head>
<body>
    <h3>Progress report: 30.01.2024</h3>
        <h4>Introduction</h4>
            <p class="text">
                Deep neural networks learn representations of stimuli. This is 
                convenient for visual neuroscience, firstly because the images
                and movies presented to an animal can be transformed with
                neural networks so that we
                can study p(response|f(stimulus)) instead of p(response|stimulus).
                Neural networks map visual stimuli from pixel space to another vector 
                space where information of interest can be easily (linearly) decoded 
                from the representation. This is called disentanglement (James Dicarlo) and it 
                simplifies our life immensely, because we can obtain re-representations of stimuli by 
                simply training a model to minimize a cost function on a task. Some forms of learning
                (such as self-supervised learning and adversarial learning) don't even require human annotated data!
                This is great for neuroscience, because if we know that a neural network can achieve
                object recognition then the representations that it learns may be ethologically
                relevant for primate vision. 
            </p>

            <img src="./img/Screenshot from 2024-01-30 01-51-26.png" width="500" height="300">
            <p class="text">Figure 1. InfoGAN learns disentangled representations where variation
                along particular dimensions of a seed vector
                determines high-level properties such as emotion and the presence of glasses 
                in generated images(infoGAN)
            </p>
            <p class="text">
                The utility of Convolutional Neural Networks (ConvNets) is well established in neuroscience.
                Ever since the original AlexNet paper that achieved state of the art on ImageNet, these
                models have been used extensively to study biological object recognition. However, ConvNets
                have an inductive bias which helps in low and medium data setting, but hinders their performance
                in the massive data regime. Specifically, ConvNets have localized receptive fields and therefore
                have difficulty
                integrating information that spans multiple parts of the image. In the language of statistical learning,
                these models have a bias problem (they are too simple to capture
                complex dependencies that are necessary for some tasks). In the abundant data and 
                compute resource regime another architecture-- the Transformer-- has beat ConvNets on computer vision 
                benchmarks. 
            </p>
            <img src="./img/Convolution_arithmetic_-_Full_padding_no_strides_transposed.gif" width="200" height="100">
            <p></p>
        <h5>Literature</h5>
            <p></p>
</body>
</html>