<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <h1>Machine Learning as Instruction Sets Compiled from Data</h1>
    <h2>Introduction</h2>
        <div>
            The popularity of Harry Potter is an indication 
            of how the human kind is endlessly fascinated by the idea of magic.
            I am not a stranger to this fascination. As a child, I dreamt
            of mind-reading, teleportation, healing powers. I grew up and 
            became a scientist and found a confirmation to the famous quote 
            "Any sufficiently advanced technology is indistinguishable from magic."
        </div>
        <div>
            This book is an attempt to explore the "magic" of machine learning algorithms
            through visual presentation and a conceptual approach that views them as 
            <i>instruction sets</i> learned from data. 
            With the advent of Large Language Models, it is almost certain that this
            technology will help us gain greater control over the universe. However,
            even though we're able to create and train these systems, we are left
            wondering how they work. Information about how these "magic spell" algorithms
            work is buried in dense research papers, graduate level courses and massive
            code repositories. This book is my attempt to make sense of it all in a way
            that is helpful for anybody who wants to better understand these "spells".
        </div>

        <div>""Every machine learning algorithm is a kind of spell â€” a compact incantation that tells a machine what patterns to recognize, what boundaries to draw, what structures to reconstruct."
            --ChatGPT
        </div>

        <h2>Matrix Decomposition</h2>

        <div>We start with the most common object in Machine Learning-- a grid of numbers,
            like a wall of LEGO bricks. This grid represents your data. It could be
            a grid of pixels in a photo, people and their movie ratings or the 
            activation patterns of neurons over time (I am a computational neuroscientist).
            Let's call this big LEGO wall matrix X. So, each little square (brick) has a number
            in it -- maybe a brightness, a score, or a measurement.
        </div>
        <div>
            The goal of matrix decomposition is to break this data grid X into
            components (U) and instructions (V) to reconstruct the original from these components.
            Each component u is a vector of the same dimensionality as the number of
            rows in the data matrix. Instruction vectors v dictate how much each 
            component contributes to the reconstruction -- the are a vector with 
            the same number of elements as the number of columns in the data matrix.
        </div>
        <div>Each component u thus has a corresponding instruction set v, and they
            are combined using multiplication. Each component and instruction set
            combination is itself a grid of the same dimensionality as X. These 
            grids are then combined via addition to yield the reconstruction of
            the original data matrix X. If we use the example of a photo,
            the components are like patterns of pixels in a 
            dataset with n images and instructions are how much of this pixel
            pattern is in each image. 
            On the other hand, if our data X consists of neural activations in time,
            the component is a pattern of activity across neurons and the instruction
            set unrolls this pattern of activity through time by weighing each pattern
            of activity differently at each time instant.

        </div>
        <div> Let's visualize how this works!</div>

    <h2>Illustrating Matrix Decomposition-- PCA and eigenfaces</h2>
        <div>We are going to use the most famous matrix decomposition algorithm,
            PCA to automatically find components and instructions to decompose
            a dataset of faces X, where each column of X is a face in pixel space (
            this means that they are flattened into a long vector).
            The components in this data are flattened eigenfaces
            and each instruction specifies a weight for how much of this "eigenface" 
            to add or subtract to reconstruct the original face.
        </div>
</body>
</html>