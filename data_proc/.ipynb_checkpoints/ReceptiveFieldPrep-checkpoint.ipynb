{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data downloaded from https://janelia.figshare.com/articles/dataset/Recordings_of_ten_thousand_neurons_in_visual_cortex_in_response_to_2_800_natural_images/6845348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsemblePursuit.EnsemblePursuit import EnsemblePursuit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.linear_model import ridge_regression\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(images,k=100):\n",
    "    images=torch.cuda.FloatTensor(images)\n",
    "    mean_im=torch.mean(images,dim=0)\n",
    "    centered=torch.sub(images,mean_im)\n",
    "    print(centered.size())\n",
    "    U,S,V=torch.svd(centered)\n",
    "    #print(U,S,V)\n",
    "    S=torch.diag(S)\n",
    "    print(U.size())\n",
    "    reduced=torch.matmul(U[:,:k],S[:k,:k])\n",
    "    #print(reduced.size())\n",
    "    reduced=torch.matmul(reduced,V[:,:k].t())\n",
    "    return np.array(reduced.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dat(dat_path,im_path):\n",
    "    dat=loadmat(dat_path)\n",
    "    #Get regression target\n",
    "    images=loadmat('C:/Users/koester_lab/Downloads/images_natimg2800_all.mat')['imgs']\n",
    "    images=images.transpose((2,0,1))\n",
    "    images=images.reshape((2800,68*270))\n",
    "    reduced_images=PCA(images)\n",
    "    #Get out of matlab convention\n",
    "    stim=dat['stim']['istim'][0][0]-1\n",
    "    #Remove the blank screen\n",
    "    stim=stim[stim!=2800]\n",
    "    reduced_images=reduced_images[stim]\n",
    "    resp = dat['stim'][0]['resp'][0]\n",
    "    resp=resp[stim]\n",
    "    print('Stim shp: ', stim.shape)\n",
    "    print('Resp shp: ', resp.shape)\n",
    "    print('Images shp: ', reduced_images.shape)\n",
    "    return stim, reduced_images, resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_path='C:/Users/koester_lab/Downloads/natimg2800_M170714_MP032_2017-08-07.mat'\n",
    "im_path='C:/Users/koester_lab/Downloads/images_natimg2800_all.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2800, 18360])\n",
      "torch.Size([2800, 2800])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 2800 but corresponding boolean dimension is 5880",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9144725bc948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_dat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-6c42e3599bd8>\u001b[0m in \u001b[0;36mprepare_dat\u001b[1;34m(dat_path, im_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'istim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Remove the blank screen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mreduced_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduced_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstim\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m2800\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stim'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'resp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mresp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstim\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m2800\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 2800 but corresponding boolean dimension is 5880"
     ]
    }
   ],
   "source": [
    "stim, reduced_images, resp = prepare_dat(dat_path,im_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
